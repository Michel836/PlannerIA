"""
Enhanced Error Handling System for PlannerIA
Provides user-friendly error messages and recovery suggestions
"""

import logging
import traceback
from typing import Dict, Any, Optional, Tuple
from datetime import datetime
import streamlit as st

logger = logging.getLogger(__name__)

class PlannerIAError(Exception):
    """Base exception for PlannerIA specific errors"""
    def __init__(self, message: str, error_code: str = None, recovery_suggestions: list = None):
        super().__init__(message)
        self.error_code = error_code
        self.recovery_suggestions = recovery_suggestions or []

class LLMConnectionError(PlannerIAError):
    """Error when LLM connection fails"""
    pass

class ValidationError(PlannerIAError):
    """Error when input validation fails"""
    pass

class ProcessingError(PlannerIAError):
    """Error during plan processing"""
    pass

class ErrorHandler:
    """Enhanced error handling with user-friendly messages"""
    
    # Error categories with user-friendly messages
    ERROR_CATEGORIES = {
        "llm_connection": {
            "title": "ðŸ”Œ ProblÃ¨me de Connexion LLM",
            "description": "Impossible de se connecter au modÃ¨le de langage",
            "suggestions": [
                "VÃ©rifiez qu'Ollama est dÃ©marrÃ© (ollama serve)",
                "Confirmez que le modÃ¨le llama3.2:latest est installÃ©",
                "VÃ©rifiez la connectivitÃ© rÃ©seau locale",
                "RedÃ©marrez le service Ollama si nÃ©cessaire"
            ],
            "technical_check": "Connexion Ollama sur http://localhost:11434"
        },
        "validation_error": {
            "title": "ðŸ“ Erreur de Validation",
            "description": "Les donnÃ©es fournies ne respectent pas le format attendu",
            "suggestions": [
                "VÃ©rifiez que votre description de projet est complÃ¨te",
                "Assurez-vous d'inclure les objectifs et le pÃ©rimÃ¨tre",
                "Utilisez un langage clair et structurÃ©",
                "Ã‰vitez les caractÃ¨res spÃ©ciaux dans les noms"
            ],
            "technical_check": "Validation des donnÃ©es d'entrÃ©e"
        },
        "processing_error": {
            "title": "âš™ï¸ Erreur de Traitement",
            "description": "Une erreur s'est produite pendant la gÃ©nÃ©ration du plan",
            "suggestions": [
                "Simplifiez votre demande de projet",
                "RÃ©duisez la complexitÃ© des exigences",
                "Tentez Ã  nouveau dans quelques secondes",
                "RedÃ©marrez l'application si le problÃ¨me persiste"
            ],
            "technical_check": "Pipeline de traitement des agents IA"
        },
        "export_error": {
            "title": "ðŸ“„ Erreur d'Export",
            "description": "Impossible de gÃ©nÃ©rer le fichier d'export",
            "suggestions": [
                "VÃ©rifiez l'espace disque disponible",
                "Assurez-vous que le dossier de destination est accessible",
                "Fermez les fichiers ouverts du mÃªme nom",
                "Tentez un export dans un format diffÃ©rent"
            ],
            "technical_check": "GÃ©nÃ©ration de rapports"
        },
        "system_error": {
            "title": "ðŸ–¥ï¸ Erreur SystÃ¨me",
            "description": "Une erreur systÃ¨me inattendue s'est produite",
            "suggestions": [
                "RedÃ©marrez l'application",
                "VÃ©rifiez les ressources systÃ¨me (RAM, CPU)",
                "Consultez les logs pour plus de dÃ©tails",
                "Contactez l'support technique si le problÃ¨me persiste"
            ],
            "technical_check": "SystÃ¨me et ressources"
        }
    }
    
    @staticmethod
    def classify_error(error: Exception) -> str:
        """Classify error type based on exception content"""
        error_str = str(error).lower()
        
        # LLM connection errors
        if any(keyword in error_str for keyword in ["connection", "ollama", "http", "timeout", "refused"]):
            return "llm_connection"
            
        # Validation errors
        if any(keyword in error_str for keyword in ["validation", "invalid", "missing", "required", "schema"]):
            return "validation_error"
            
        # Export errors
        if any(keyword in error_str for keyword in ["pdf", "csv", "export", "file", "write", "permission"]):
            return "export_error"
            
        # Processing errors
        if any(keyword in error_str for keyword in ["processing", "generation", "agent", "crew", "pipeline"]):
            return "processing_error"
            
        # Default to system error
        return "system_error"
    
    @staticmethod
    def handle_error(error: Exception, context: str = "", show_technical_details: bool = False) -> Dict[str, Any]:
        """
        Handle error with user-friendly feedback
        
        Args:
            error: The exception that occurred
            context: Additional context about where the error occurred
            show_technical_details: Whether to show technical error details
            
        Returns:
            Dict with error information and UI components
        """
        error_category = ErrorHandler.classify_error(error)
        error_info = ErrorHandler.ERROR_CATEGORIES[error_category]
        
        # Log the error
        logger.error(f"Error in {context}: {error}", exc_info=True)
        
        # Create error response
        error_response = {
            "error": True,
            "category": error_category,
            "title": error_info["title"],
            "description": error_info["description"],
            "suggestions": error_info["suggestions"],
            "technical_check": error_info["technical_check"],
            "context": context,
            "timestamp": datetime.now().isoformat(),
            "original_error": str(error)
        }
        
        # Display user-friendly error in Streamlit
        ErrorHandler.display_error_ui(error_response, show_technical_details)
        
        return error_response
    
    @staticmethod
    def display_error_ui(error_info: Dict[str, Any], show_technical_details: bool = False):
        """Display user-friendly error UI in Streamlit"""
        
        # Main error message
        st.error(f"{error_info['title']}")
        
        # Error description
        st.markdown(f"**Description:** {error_info['description']}")
        
        # Recovery suggestions
        with st.expander("ðŸ’¡ Suggestions de rÃ©solution", expanded=True):
            for i, suggestion in enumerate(error_info["suggestions"], 1):
                st.markdown(f"{i}. {suggestion}")
        
        # System check
        with st.expander("ðŸ” VÃ©rification systÃ¨me"):
            st.info(f"**Zone Ã  vÃ©rifier:** {error_info['technical_check']}")
            
            # Add quick diagnostic buttons
            col1, col2, col3 = st.columns(3)
            
            with col1:
                if st.button("ðŸ”„ RÃ©essayer", key="retry_button"):
                    st.experimental_rerun()
            
            with col2:
                if st.button("ðŸ§¹ Nettoyer Cache", key="clear_cache_button"):
                    st.cache_data.clear()
                    st.success("Cache nettoyÃ©!")
            
            with col3:
                if st.button("ðŸ“Š Ã‰tat SystÃ¨me", key="system_status_button"):
                    ErrorHandler.show_system_status()
        
        # Technical details (collapsible)
        if show_technical_details:
            with st.expander("ðŸ”§ DÃ©tails techniques"):
                st.code(f"""
CatÃ©gorie: {error_info['category']}
Contexte: {error_info['context']}
Horodatage: {error_info['timestamp']}
Erreur originale: {error_info['original_error']}
                """)
    
    @staticmethod
    def show_system_status():
        """Show system status diagnostics"""
        import psutil
        import os
        
        try:
            # System metrics
            cpu_percent = psutil.cpu_percent(interval=1)
            memory = psutil.virtual_memory()
            disk = psutil.disk_usage('.')
            
            # Display metrics
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("ðŸ–¥ï¸ CPU", f"{cpu_percent:.1f}%")
            
            with col2:
                st.metric("ðŸ§  RAM", f"{memory.percent:.1f}%", 
                         f"{memory.available // (1024**3)} GB libre")
            
            with col3:
                st.metric("ðŸ’¾ Disque", f"{disk.percent:.1f}%",
                         f"{disk.free // (1024**3)} GB libre")
            
            # Service checks
            st.markdown("**Ã‰tat des Services:**")
            
            # Check Ollama
            try:
                import requests
                response = requests.get("http://localhost:11434/api/tags", timeout=2)
                if response.status_code == 200:
                    st.success("âœ… Ollama: OpÃ©rationnel")
                else:
                    st.error("âŒ Ollama: ProblÃ¨me de connexion")
            except Exception:
                st.error("âŒ Ollama: Non accessible")
            
            # Check data directories
            data_dirs = ["data/models", "data/reports", "data/runs"]
            for dir_path in data_dirs:
                if os.path.exists(dir_path):
                    st.success(f"âœ… {dir_path}: Accessible")
                else:
                    st.warning(f"âš ï¸ {dir_path}: Manquant")
                    
        except Exception as e:
            st.error(f"Impossible d'obtenir l'Ã©tat systÃ¨me: {e}")
    
    @staticmethod
    def create_error_recovery_guide() -> str:
        """Create a comprehensive error recovery guide"""
        guide = """
# ðŸ› ï¸ Guide de RÃ©solution des Erreurs PlannerIA

## Erreurs Courantes et Solutions

### 1. ProblÃ¨me de Connexion LLM
**SymptÃ´mes:** "Connection refused", "Ollama not responding"
**Solutions:**
- DÃ©marrer Ollama: `ollama serve`
- VÃ©rifier le modÃ¨le: `ollama list`
- Installer le modÃ¨le: `ollama pull llama3.2:latest`

### 2. Erreur de GÃ©nÃ©ration de Plan
**SymptÃ´mes:** "Plan generation failed", "Processing error"
**Solutions:**
- Simplifier la description du projet
- VÃ©rifier la syntaxe et la clartÃ©
- RedÃ©marrer l'application

### 3. ProblÃ¨me d'Export
**SymptÃ´mes:** "Export failed", "File generation error"
**Solutions:**
- VÃ©rifier l'espace disque
- Fermer les fichiers ouverts
- RÃ©essayer avec un nom diffÃ©rent

### 4. Erreur de Performance
**SymptÃ´mes:** Application lente, timeouts
**Solutions:**
- Fermer d'autres applications
- VÃ©rifier RAM et CPU
- Simplifier les demandes

## Contacts Support
- Documentation: Consultez la documentation du projet
- Logs: VÃ©rifiez les logs dans la console
- RedÃ©marrage: Relancez l'application complÃ¨te
        """
        return guide

# Convenience functions for common error scenarios
def handle_llm_error(error: Exception, context: str = "LLM Operation") -> Dict[str, Any]:
    """Handle LLM-specific errors"""
    return ErrorHandler.handle_error(LLMConnectionError(str(error)), context)

def handle_validation_error(error: Exception, context: str = "Input Validation") -> Dict[str, Any]:
    """Handle validation errors"""
    return ErrorHandler.handle_error(ValidationError(str(error)), context)

def handle_processing_error(error: Exception, context: str = "Plan Processing") -> Dict[str, Any]:
    """Handle processing errors"""
    return ErrorHandler.handle_error(ProcessingError(str(error)), context)

def handle_export_error(error: Exception, context: str = "Export Operation") -> Dict[str, Any]:
    """Handle export errors"""
    return ErrorHandler.handle_error(error, context)

def safe_execute(func, *args, context: str = "", **kwargs) -> Tuple[bool, Any]:
    """
    Safely execute a function with enhanced error handling
    
    Returns:
        Tuple of (success: bool, result: Any)
    """
    try:
        result = func(*args, **kwargs)
        return True, result
    except Exception as e:
        error_info = ErrorHandler.handle_error(e, context)
        return False, error_info